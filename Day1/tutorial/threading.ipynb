{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f03c3d4f",
   "metadata": {},
   "source": [
    "# Parallel programming in Python \n",
    "## Thread-based parallelism using the concurrent.futures (& threading module)\n",
    "\n",
    "\n",
    "The [concurrent.futures](https://docs.python.org/3/library/concurrent.futures.html) modules provides interfaces for running tasks using pools of thread or process workers. The APIs are the same, so applications can switch between threads and processes with minimal changes.\n",
    "\n",
    "The [threading](https://docs.python.org/3/library/threading.html) module - includes a high-level, object oriented, API for working with concurrency from Python. Thread objects run concurrently within the same process and share memory with other thread objects. Using threads is an easy way to scale for tasks that are more I/O bound than CPU bound. The python threading module is used to manage the execution of threads within a process. It allows a program to run multiple operations concurrently in the same process space.\n",
    "\n",
    "----\n",
    "----"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b2f1bfb-47fa-499a-8cf0-e97d3c98a0ab",
   "metadata": {},
   "source": [
    "### The Global Interpreter Lock\n",
    "In CPython, the global interpreter lock, or GIL, is a mutex that protects access to Python objects, preventing multiple threads from executing Python bytecodes at once. The GIL prevents race conditions and ensures thread safety. \n",
    "\n",
    "\n",
    "![GIL](https://miro.medium.com/max/1400/0*EhguHDUThWcWlotK.png)\n",
    "*Example Diagram of the GIL in action. Credit Medium.com*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "56736846",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Worker\n",
      "Worker\n",
      "Worker\n",
      "Worker\n",
      "Worker\n"
     ]
    }
   ],
   "source": [
    "import threading\n",
    "\n",
    "def worker():\n",
    "    \"\"\"thread worker function\"\"\"\n",
    "    print('Worker')\n",
    "\n",
    "\n",
    "threads = []\n",
    "for i in range(5):\n",
    "    t = threading.Thread(target=worker)\n",
    "    threads.append(t)\n",
    "    t.start()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "884667b1",
   "metadata": {},
   "source": [
    "It is useful to be able to spawn a thread and pass it arguments to tell it what work to do. Any type of object can be passed as argument to the thread. This example passes a number, which the thread prints."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "59cc0d3b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Worker: 0\n",
      "Worker: 1\n",
      "Worker: 2\n",
      "Worker: 3\n",
      "Worker: 4\n"
     ]
    }
   ],
   "source": [
    "import threading\n",
    "import time\n",
    "\n",
    "def worker(worker_id):\n",
    "    \"\"\"thread worker function\"\"\"\n",
    "    time.sleep(worker_id)\n",
    "    print('Worker: %s' % worker_id)\n",
    "    \n",
    "threads = []\n",
    "for i in range(5):\n",
    "    t = threading.Thread(target=worker, args=[i])\n",
    "    threads.append(t)\n",
    "    t.start()\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c49683a1",
   "metadata": {},
   "source": [
    "In order to identify the current thread one can use:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d2396fc6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MainThread\n",
      "2393637\n"
     ]
    }
   ],
   "source": [
    "print(threading.current_thread().name)\n",
    "print(threading.current_thread().native_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "476a742d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Worker name: ben_0\n",
      "Worker native id: 2402538\n",
      "Worker number: 0\n",
      "Worker name: ben_1\n",
      "Worker native id: 2402539\n",
      "Worker number: 1\n",
      "Worker name: ben_2\n",
      "Worker native id: 2402540\n",
      "Worker number: 2\n",
      "Worker name: ben_3\n",
      "Worker native id: 2402541\n",
      "Worker number: 3\n",
      "Worker name: ben_4\n",
      "Worker native id: 2402542\n",
      "Worker number: 4\n"
     ]
    }
   ],
   "source": [
    "import threading\n",
    "import time\n",
    "\n",
    "def worker(worker_id):\n",
    "    \"\"\"thread worker function\"\"\"\n",
    "    time.sleep(worker_id)\n",
    "    print('Worker name: {}'.format(threading.current_thread().name))\n",
    "    print('Worker native id: {}'.format(threading.current_thread().native_id))\n",
    "    print('Worker number: {}'.format(worker_id))\n",
    "    \n",
    "\n",
    "threads = []\n",
    "for i in range(5):\n",
    "    t = threading.Thread(target=worker, args=[i], name=\"ben_{}\".format(i))\n",
    "    threads.append(t)\n",
    "    t.start()\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f34d03e0",
   "metadata": {},
   "source": [
    "----\n",
    "\n",
    "## Deamons vs. Non-deamons threads\n",
    "\n",
    "Up to this point, the examples above have implicitly waited for all threads to complete their work before exiting (these are called Non-deamon threads). Sometimes it is beneficial for programs to spawn a thread as a daemon which will run without blocking the main program from exiting.\n",
    "\n",
    "Using daemon threads is useful for services where there may not be an easy way to interrupt the thread, or where letting the thread die in the middle of its work does not lose or corrupt data (for example, a thread that generates “heart beats” for a service monitoring tool). To mark a thread as a daemon, pass `daemon=True` when constructing it or call its `set_daemon()` method with `True`. \n",
    "\n",
    "The default is for threads (in the threading module) to not be daemons.\n",
    "\n",
    "----"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "b3a9fcbb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting tdeamons.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile tdeamons.py\n",
    "import threading\n",
    "import time\n",
    "import logging\n",
    "\n",
    "def daemon(duration):\n",
    "    print('Starting {} and sleeping for {} secs'.format(threading.current_thread().name,duration))\n",
    "    time.sleep(duration)\n",
    "    print('Exiting',threading.current_thread().name)\n",
    "\n",
    "\n",
    "def non_daemon(duration):\n",
    "    print('Starting {} and sleeping for {} secs'.format(threading.current_thread().name,duration))\n",
    "    time.sleep(duration)\n",
    "    print('Exiting',threading.current_thread().name)\n",
    "\n",
    "d = threading.Thread(name='daemon', target=daemon,args=[5],daemon=True)\n",
    "\n",
    "t = threading.Thread(name='non-daemon', target=non_daemon,args=[2],daemon=False)\n",
    "\n",
    "d.start()\n",
    "t.start()\n",
    "\n",
    "#d.join()\n",
    "print(\"Program finished\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45277577",
   "metadata": {},
   "source": [
    "If you want the main program (thread) to wait until a daemon thread has completed its work, use the `join()` method. (Try it in the previous example!)\n",
    "\n",
    "- By default, `join()` blocks indefinitely. It is also possible to pass a float value representing the number of seconds to wait for the thread to become inactive. If the thread does not complete within the timeout period, `join()` returns anyway.\n",
    "- `join()` is useful not only with deamon threads, as it can act as a barrier for non-Daemon threads."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "06285808",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting daemon and sleeping for 5 secs\n",
      "Starting non-daemon and sleeping for 2 secs\n",
      "Program finished\n",
      "Exiting non-daemon\n"
     ]
    }
   ],
   "source": [
    "!python tdeamons.py"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72e09cc8",
   "metadata": {},
   "source": [
    "----\n",
    "\n",
    "## Enumerating over all active threads\n",
    "\n",
    "It is not necessary to retain an explicit handle to all of the daemon threads in order to ensure they have completed before exiting the main process. `enumerate()` returns a list of active Thread instances. The list includes the current thread, and since joining the current thread introduces a deadlock situation, it must be skipped.\n",
    "\n",
    "----"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "077bbfbf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<_MainThread(MainThread, started 23030073861952)>\n",
      "<Thread(IOPub, started daemon 23029775521536)>\n",
      "<Heartbeat(Heartbeat, started daemon 23029773420288)>\n",
      "<Thread(Thread-3 (_watch_pipe_fd), started daemon 23029767116544)>\n",
      "<Thread(Thread-4 (_watch_pipe_fd), started daemon 23029765015296)>\n",
      "<ControlThread(Control, started daemon 23029762914048)>\n",
      "<HistorySavingThread(IPythonHistorySavingThread, started 23029760812800)>\n",
      "<ParentPollerUnix(Thread-2, started daemon 23029757662976)>\n"
     ]
    }
   ],
   "source": [
    "import threading\n",
    "#print out all active threads\n",
    "for t in threading.enumerate():\n",
    "    print(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "399a060e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing print_active_threads.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile print_active_threads.py\n",
    "import threading\n",
    "#print out all active threads\n",
    "for t in threading.enumerate():\n",
    "    print(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "2ac83c5e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<_MainThread(MainThread, started 22402778818368)>\n"
     ]
    }
   ],
   "source": [
    "!python print_active_threads.py"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ac413b8",
   "metadata": {},
   "source": [
    "# concurrent.futures\n",
    "\n",
    "[concurrent.futures](https://docs.python.org/3/library/concurrent.futures.html)\n",
    "\n",
    "The concurrent.futures modules provides interfaces for running tasks using pools of thread or process workers. The APIs are the same, so applications can switch between threads and processes with minimal changes.\n",
    "\n",
    "The module provides two types of classes for interacting with the pools. \n",
    "\n",
    "```Executors``` are used for managing pools of workers, and ```futures``` are used for managing results computed by the workers. \n",
    "\n",
    "To use a pool of workers, an application creates an instance of the appropriate executor class and then submits tasks for it to run. When each task is started, a Future instance is returned. \n",
    "\n",
    "When the result of the task is needed, an application can "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60eb683e",
   "metadata": {},
   "source": [
    "### Executor Objects \n",
    "\n",
    "An abstract class that provides methods to execute calls asynchronously. It should not be used directly, but through its concrete subclasses.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b095827c",
   "metadata": {},
   "source": [
    "### Future Objects\n",
    "\n",
    "The Future class encapsulates the asynchronous execution of a callable. Future instances are created by `Executor.submit()`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a43e3ab6",
   "metadata": {},
   "source": [
    "### ThreadPoolExecutor\n",
    "\n",
    "ThreadPoolExecutor is an Executor subclass that uses a pool of threads to execute calls asynchronously. ThreadPoolExecutor manages a set of worker threads, passing tasks to them as they become available for more work. \n",
    "\n",
    "This example uses map() to concurrently produce a set of results from an input iterable. The task uses ```time.sleep()``` to pause a different amount of time to demonstrate that, regardless of the order of execution of concurrent tasks, ```map()``` always returns the values in order based on the inputs."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09c5ecb3-2d35-4437-a8a5-09b4f1106e5b",
   "metadata": {},
   "source": [
    "## Pools of threads\n",
    "\n",
    "![threadpool](https://drek4537l1klr.cloudfront.net/terrell/Figures/c07-02.png)\n",
    "*Example image from https://livebook.manning.com*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "24899e47",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MainThread: is starting work\n",
      "ThreadPoolExecutor-20_0 with ID 2435035: is sleeping for 2 seconds\n",
      "ThreadPoolExecutor-20_1 with ID 2435036: is sleeping for 3 seconds\n",
      "ThreadPoolExecutor-20_2 with ID 2435037: is sleeping for 4 seconds\n",
      "MainThread: is waiting for the results\n",
      "ThreadPoolExecutor-20_0: done with 2\n",
      "ThreadPoolExecutor-20_1: done with 3\n",
      "ThreadPoolExecutor-20_2: done with 4\n",
      "main: results: [20.0, 30.0, 40.0]\n"
     ]
    }
   ],
   "source": [
    "from concurrent import futures\n",
    "import threading\n",
    "import time\n",
    "\n",
    "\n",
    "def task(n):\n",
    "    print('{} with ID {}: is sleeping for {} seconds'.format(threading.current_thread().name,threading.current_thread().native_id,n))\n",
    "    time.sleep(n)\n",
    "    print('{}: done with {}'.format(threading.current_thread().name,n))\n",
    "    return n * 10.\n",
    "\n",
    "\n",
    "#Initiate the threads\n",
    "ex = futures.ThreadPoolExecutor(max_workers=3)\n",
    "print('{}: is starting work'.format(threading.current_thread().name))\n",
    "\n",
    "# Start the threads with the map method\n",
    "# Here we spawn 3 threads, with \"ids\" from 2,3,4\n",
    "results = ex.map(task, [2,3,4])\n",
    "\n",
    "print('{}: is waiting for the results'.format(threading.current_thread().name))\n",
    "real_results = list(results)\n",
    "print('main: results: {}'.format(real_results))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f184ffa-c747-4b73-be24-e833323046a4",
   "metadata": {},
   "source": [
    "### Get fine/r grained control with the use of the submit() method.\n",
    "You control when worker gets submitted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "8a6c1951",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MainThread: Starting\n",
      "ThreadPoolExecutor-14_0: sleeping 10\n",
      "future object: MainThread\n",
      "MainThread: waiting for results\n",
      "ThreadPoolExecutor-14_0: done with 10\n",
      "MainThread: result: 100.0\n",
      "MainThread: future after result: <Future at 0x14f1d3810610 state=finished returned float>\n"
     ]
    }
   ],
   "source": [
    "from concurrent import futures\n",
    "import threading\n",
    "import time\n",
    "\n",
    "\n",
    "def task(n):\n",
    "    print('{}: sleeping {}'.format(threading.current_thread().name,n))\n",
    "    time.sleep(n)\n",
    "    print('{}: done with {}'.format(threading.current_thread().name,n))\n",
    "    return n * 10.\n",
    "\n",
    "ex = futures.ThreadPoolExecutor(max_workers=2)\n",
    "\n",
    "print('{}: Starting'.format(threading.current_thread().name))\n",
    "f = ex.submit(task, 10)\n",
    "\n",
    "print('future object: {}'.format(threading.current_thread().name,f))\n",
    "print('{}: waiting for results'.format(threading.current_thread().name))\n",
    "result = f.result()\n",
    "\n",
    "\n",
    "print('{}: result: {}'.format(threading.current_thread().name,result))\n",
    "print('{}: future after result: {}'.format(threading.current_thread().name,f))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe9faa26",
   "metadata": {},
   "source": [
    "### LET OP deadlocks ahead!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "f4a54256",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting future_deadlock.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile future_deadlock.py\n",
    "import time\n",
    "from concurrent import futures\n",
    "def wait_on_b():\n",
    "    time.sleep(1)\n",
    "    print(b.result(timeout=10))  # b will never complete because it is waiting on a.\n",
    "    return 1\n",
    "\n",
    "def wait_on_a():\n",
    "    time.sleep(5)\n",
    "    print(a.result())  # a will never complete because it is waiting on b.\n",
    "    return 1\n",
    "\n",
    "\n",
    "executor = futures.ThreadPoolExecutor(max_workers=2)\n",
    "a = executor.submit(wait_on_b)\n",
    "b = executor.submit(wait_on_a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "cfd8bd45",
   "metadata": {},
   "outputs": [],
   "source": [
    "!python future_deadlock.py"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9508897f",
   "metadata": {},
   "source": [
    "# Futher information on controlling threads (via the threading module)\n",
    "\n",
    "- Lock objects https://docs.python.org/3/library/threading.html#lock-objects\n",
    "    - A primitive lock is a synchronization primitive that is not owned by a particular thread when locked. In Python, it is currently the lowest level synchronization primitive available, implemented directly by the _thread extension module.\n",
    "- RLock objects https://docs.python.org/3/library/threading.html#rlock-objects\n",
    "    - A reentrant lock is a synchronization primitive that may be acquired multiple times by the same thread. Internally, it uses the concepts of “owning thread” and “recursion level” in addition to the locked/unlocked state used by primitive locks. In the locked state, some thread owns the lock; in the unlocked state, no thread owns it.\n",
    "- Condition objects https://docs.python.org/3/library/threading.html#condition-objects\n",
    "    - A condition variable is always associated with some kind of lock; this can be passed in or one will be created by default. Passing one in is useful when several condition variables must share the same lock. The lock is part of the condition object: you don’t have to track it separately.\n",
    "- Semephore objects https://docs.python.org/3/library/threading.html#semaphore-objects\n",
    "    - A semaphore manages an internal counter which is decremented by each acquire() call and incremented by each release() call. The counter can never go below zero; when acquire() finds that it is zero, it blocks, waiting until some other thread calls release().\n",
    "- Event objects https://docs.python.org/3/library/threading.html#event-objects\n",
    "    - This is one of the simplest mechanisms for communication between threads: one thread signals an event and other threads wait for it."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
