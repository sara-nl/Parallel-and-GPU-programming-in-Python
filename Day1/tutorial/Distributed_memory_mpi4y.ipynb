{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Distributed memory parallelism with mpi4py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## mpi4py basics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In MPI for Python, `Comm` is the base class of communicators. \n",
    "\n",
    "The two available predefined intracommunicator instances are `COMM_SELF` and `COMM_WORLD`. \n",
    "\n",
    "The number of processes in a communicator and the calling process rank can be respectively obtained with methods `Get_size()` and `Get_rank()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting communicator.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile communicator.py\n",
    "from mpi4py import MPI\n",
    "\n",
    "comm = MPI.COMM_WORLD\n",
    "size = comm.Get_size()\n",
    "rank = comm.Get_rank()\n",
    "\n",
    "print('Number of processes is %i.' %size)\n",
    "print('Hello, I am process %i.' % rank)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To run an MPI-enabled Python application, one can use command **`mpirun -np .. python3 myprog.py`**, where users can specify how many processes MPI should start. \n",
    "\n",
    "The `mpirun` command below starts two-processes to run the `communicator.py` script. Each process gets the total number of processes and its own rank number."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of processes is 2.\r\n",
      "Hello, I am process 0.\r\n",
      "Number of processes is 2.\r\n",
      "Hello, I am process 1.\r\n"
     ]
    }
   ],
   "source": [
    "!mpirun -np 2 --oversubscribe python3 communicator.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When we run this program with ```mpirun```, the code is executed by all processors in the communicator. \n",
    "We need somehow to differentiate the work if we want to use efficiently MPI.\n",
    "\n",
    "From the example above, try to make process ```rank == 0``` to print ```Hoi. Ik ben process 0``` instead.\n",
    "You can use python syntax!!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing communicator_mod.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile communicator_mod.py\n",
    "from mpi4py import MPI\n",
    "\n",
    "comm = MPI.COMM_WORLD\n",
    "size = comm.Get_size()\n",
    "rank = comm.Get_rank()\n",
    "\n",
    "# continue from here\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hoi. Ik ben process 0\r\n"
     ]
    }
   ],
   "source": [
    "!mpirun --oversubscribe -np 2 python3 communicator_mod.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To look up the communication function definition, one can use `help(...)` as shown below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on built-in function Get_rank:\n",
      "\n",
      "Get_rank(...) method of mpi4py.MPI.Intracomm instance\n",
      "    Comm.Get_rank(self)\n",
      "    \n",
      "    Return the rank of this process in a communicator\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from mpi4py import MPI\n",
    "help(MPI.COMM_WORLD.Get_rank)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mpi4py import MPI\n",
    "MPI.COMM_WORLD.Get_rank??"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Collective Communications"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Collective communications allow the communication of data between multiple processes of a group simultaneously. \n",
    "Collective functions come in blocking versions only.\n",
    "![mpi_coll_com](https://hpc-tutorials.llnl.gov/mpi/images/collective_comm.gif)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Broadcast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting broadcast.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile broadcast.py\n",
    "from mpi4py import MPI\n",
    "comm = MPI.COMM_WORLD\n",
    "print(\"Hello\")\n",
    "if comm.rank == 0:\n",
    "    data = [1,2,3,4]\n",
    "else:\n",
    "    data = None\n",
    "\n",
    "data = comm.bcast(data)\n",
    "print(\"rank:\", comm.rank, \"data:\", data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello\r\n",
      "Hello\r\n",
      "rank: 0 data: [1, 2, 3, 4]\r\n",
      "rank: 1 data: [1, 2, 3, 4]\r\n",
      "Hello\r\n",
      "rank: 2 data: [1, 2, 3, 4]\r\n",
      "Hello\r\n",
      "rank: 3 data: [1, 2, 3, 4]\r\n"
     ]
    }
   ],
   "source": [
    "!mpirun -np 4 --oversubscribe python3 broadcast.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scatter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting scatter.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile scatter.py\n",
    "from mpi4py import MPI\n",
    "comm = MPI.COMM_WORLD\n",
    "\n",
    "if comm.rank == 0:\n",
    "    data = [1,2,3,4]\n",
    "else:\n",
    "    data = None\n",
    "\n",
    "data = comm.scatter(data)\n",
    "print(\"rank:\", comm.rank, \"data:\", data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rank: 0 data: 1\r\n",
      "rank: 1 data: 2\r\n",
      "rank: 2 data: 3\r\n",
      "rank: 3 data: 4\r\n"
     ]
    }
   ],
   "source": [
    "!mpirun --oversubscribe -np 4 python3 scatter.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gather"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting gather.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile gather.py\n",
    "from mpi4py import MPI\n",
    "comm = MPI.COMM_WORLD\n",
    "\n",
    "data = comm.rank\n",
    "gathered_data = comm.gather(data, root=0)\n",
    "\n",
    "if comm.rank == 0:\n",
    "    print(\"rank:\", comm.rank, \"data:\", data)\n",
    "    print(\"rank:\", comm.rank, \"data:\", gathered_data)\n",
    "else:\n",
    "    print(\"rank:\", comm.rank, \"data:\", data)\n",
    "    print(\"rank:\", comm.rank, \"gathered data:\", gathered_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rank: 3 data: 3\r\n",
      "rank: 3 gathered data: None\r\n",
      "rank: 2 data: 2\r\n",
      "rank: 2 gathered data: None\r\n",
      "rank: 0 data: 0\r\n",
      "rank: 0 data: [0, 1, 2, 3]\r\n",
      "rank: 1 data: 1\r\n",
      "rank: 1 gathered data: None\r\n"
     ]
    }
   ],
   "source": [
    "!mpirun --oversubscribe -np 4 python3 gather.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reduction\n",
    "\n",
    "To explain the reduction we are going to use the \"PI with Montecarlo\" example."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://upload.wikimedia.org/wikipedia/commons/thumb/2/20/MonteCarloIntegrationCircle.svg/1024px-MonteCarloIntegrationCircle.svg.png\" alt=\"drawing\" width=\"400\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "    \\pi \\approx \\frac{A_{circle}}{A_{square}} =>  \\sum_{0}^{N_{iter}} \\frac{N_{inside}}{N_{total}}   \n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.4409689903259277\n",
      "pi = 3.1417604\n",
      "% error = 0.005339534067478378\n"
     ]
    }
   ],
   "source": [
    "#Serial Example\n",
    "import time \n",
    "from random import random \n",
    "\n",
    "count = 0\n",
    "Niter = 10000000\n",
    "\n",
    "t1 = time.time()\n",
    "for i in range(0,Niter):\n",
    "    (x,y) = (random(), random())\n",
    "    if (x * x) + (y * y) <= 1.0:\n",
    "        count += 1\n",
    "t2 = time.time()\n",
    "\n",
    "print(t2-t1)\n",
    "\n",
    "pi = 4.0 * count / Niter\n",
    "print(\"pi = {}\".format(pi))\n",
    "print(\"% error = {}\".format(abs(pi - 3.14159265359)/3.14159265359*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting reduction_pi.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile reduction_pi.py\n",
    "from mpi4py import MPI\n",
    "from random import random \n",
    "comm = MPI.COMM_WORLD\n",
    "\n",
    "count = 0\n",
    "Niter = 10000000\n",
    "\n",
    "t1 = MPI.Wtime()\n",
    "for i in range(0,Niter,comm.size):\n",
    "    (x,y) = (random(), random())\n",
    "    if (x * x) + (y * y) <= 1.0:\n",
    "        count += 1\n",
    "\n",
    "sum_count = comm.reduce(count, MPI.SUM)\n",
    "t2 = MPI.Wtime()\n",
    "\n",
    "if comm.rank == 0:\n",
    "    print(t2-t1)\n",
    "    pi = 4.0 * sum_count / Niter\n",
    "    print(\"pi = {}\".format(pi))\n",
    "    print(\"% error = {}\".format(abs(pi - 3.14159265359)/3.14159265359*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.248424767\r\n",
      "pi = 3.1414944\r\n",
      "% error = 0.0031275089050059957\r\n"
     ]
    }
   ],
   "source": [
    "!mpirun --oversubscribe -np 3 python3 reduction_pi.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are interested in performances. Let's time it with Python."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Point-to-Point Communications."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Point to point communication enables the transmission of data between a pair of processes, one side sending, the other reciving. MPI provides a set of *send* and *receive* functions allowing the communication of *typed* data with an associated *tag*."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Blocking Communications"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Blocking functions in MPI block the caller until the data buffers involved in the communication can be safely reused by the application program."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting sendrecv.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile sendrecv.py\n",
    "from mpi4py import MPI\n",
    "comm = MPI.COMM_WORLD\n",
    "\n",
    "if comm.rank == 0:\n",
    "    comm.send(\"Hello world\", 1)\n",
    "\n",
    "if comm.rank == 0:\n",
    "    message = comm.recv()\n",
    "    print(\"Rank 1 received '%s'\" %\n",
    "          message)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "^C\r\n"
     ]
    }
   ],
   "source": [
    "!mpirun -np 2 --oversubscribe python3 sendrecv.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's now take a look at the Alice/Bob example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting alicebob.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile alicebob.py\n",
    "from mpi4py import MPI\n",
    "comm = MPI.COMM_WORLD\n",
    "\n",
    "# Alice; say Hello to Bob\n",
    "if comm.rank == 0:\n",
    "    comm.ssend(\"Hello Bob!\", 1)\n",
    "    mesg = comm.srecv()\n",
    "    print(\"Alice: Bob said {}\".format(mesg))\n",
    "\n",
    "# Bob; say Hello to Alice\n",
    "if comm.rank == 1:\n",
    "    comm.ssend(\"Hello Alice!\", 0)\n",
    "    mesg = comm.srecv()\n",
    "    print(\"Bob: Alice said {}\".format(mesg))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "^C\r\n"
     ]
    }
   ],
   "source": [
    "!mpirun -np 2 --oversubscribe python3 alicebob.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MPI implementation usually eager-send small messages so ```MPI_Send()``` can return immediately, but this is an implementation choice not mandated by the standard, and \"small\" message depends on the library version, the interconnect you are using and other factors."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Trying changing the above ```comm.send``` with the secure ```comm.ssend``` and see what happens.\n",
    "\n",
    "Can you solve the deadlock?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Nonblocking Communications."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nonblocking send and receive functions return immediately after *send/receive* operation. This means the process can continue to do something else, e.g. computation and check the status of the *send/receive* operation later.\n",
    "This gives the possibility of overlapping communication and computation, such that the performance of the program can be increased."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting p2pisendirecv.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile p2pisendirecv.py\n",
    "from mpi4py import MPI\n",
    "\n",
    "comm = MPI.COMM_WORLD\n",
    "rank = comm.Get_rank()\n",
    "\n",
    "start = MPI.Wtime()\n",
    "\n",
    "if rank == 0:\n",
    "    data = {'a': 7, 'b': 3.14} \n",
    "    req = comm.isend(data, dest=1, tag=11)\n",
    "    req.wait()\n",
    "elif rank == 1:\n",
    "    req = comm.irecv(source=0, tag=11)\n",
    "    data = req.wait()\n",
    "\n",
    "end = MPI.Wtime()\n",
    "elapsed = end - start\n",
    "\n",
    "print(\"Rank {}: Elapsed time is {} seconds.  Data is {}.\".format(rank, elapsed, data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rank 1: Elapsed time is 6.0308e-05 seconds.  Data is {'a': 7, 'b': 3.14}.\r\n",
      "Rank 0: Elapsed time is 3.2755e-05 seconds.  Data is {'a': 7, 'b': 3.14}.\r\n"
     ]
    }
   ],
   "source": [
    "!mpirun -np 2 --oversubscribe python3 p2pisendirecv.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise**:\n",
    "\n",
    "Let each MPI process create a 10-elements numpy array, initialized with its own rank number.\n",
    "Let process 0 calculate the total sum of all numpy arrays element-wise.\n",
    "You can use the hints and template given below.\n",
    "\n",
    "```\n",
    "from mpi4py import MPI\n",
    "import numpy as np\n",
    "\n",
    "comm = MPI.COMM_WORLD\n",
    "rank =                 # get process rank\n",
    "size =                 # get total number of processes\n",
    "\n",
    "sendbuf = np.zeros(10, dtype='i') + rank\n",
    "recvbuf = None\n",
    "if rank == 0:\n",
    "  recvbuf = np.zeros(10, dtype='i')\n",
    "comm.Reduce(, , op= , root=0)    # What should be reduced? And which operation is used?\n",
    "\n",
    "if rank == 0:\n",
    "  sum = sum(range(size))\n",
    "  assert (recvbuf[:]==sum).all()\n",
    "  print(recvbuf)\n",
    "```\n",
    "\n",
    "The result of the exercise should look like:\n",
    "\n",
    "```\n",
    "$mpirun -np 4 python3 reducenumpy.py \n",
    "[6 6 6 6 6 6 6 6 6 6]\n",
    "```\n",
    "\n",
    "```\n",
    "$mpirun -np 5 python3 reducenumpy.py \n",
    "[10 10 10 10 10 10 10 10 10 10]\n",
    "```\n",
    "\n",
    "**Extra:** can you make Rank = 1 print the results?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Working with numpy array "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MPI for Python can communicate any built-in or user-defined Python object by using the Python pickle module under the hood.\n",
    "\n",
    "It also supports direct communication of any object exporting the single-segment buffer interface (e.g. Numpy arrays) with negligible overhead.\n",
    "\n",
    "The Python buffer protocol is a framework in which Python objects can expose raw byte arrays to other Python objects.  Using the buffer protocol, we can let multiple objects efficiently manipulate views of the same data buffers, without having to make copies of the often large datasets.\n",
    "\n",
    "As seen in the above examples, communication of generic Python objects makes use of **all-lowercase** methods of the `Comm` class, i.e. `send()`, `recv()`, `isend()`, etc.\n",
    "\n",
    "To communicate buffer-like objects, one has to use method names starting with an **upper-case** letter, like `Send()`, `Recv()`, `Bcast()`, etc.\n",
    "\n",
    "In general, buffer arguments to these calls must be explicitly specified by using a tuple like ```[data, MPI.DOUBLE]```, or ```[data, MPI.INT]```."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's see two examples using both methods:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting p2psendrecv.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile p2psendrecv.py\n",
    "from mpi4py import MPI\n",
    "\n",
    "comm = MPI.COMM_WORLD\n",
    "rank = comm.Get_rank()\n",
    "\n",
    "# initialize data\n",
    "if rank == 0:\n",
    "    data = [i for i in range(1000)]\n",
    "# measure communication time\n",
    "start = MPI.Wtime()\n",
    "if rank == 0:\n",
    "    comm.send(data, dest=1, tag=11)\n",
    "elif rank == 1:\n",
    "    data = comm.recv(source=0, tag=11)\n",
    "\n",
    "end = MPI.Wtime()\n",
    "elapsed = end - start\n",
    "\n",
    "print(\"Rank {} Elapsed time is {} seconds.\".format(rank, elapsed))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rank 0 Elapsed time is 7.2626e-05 seconds.\r\n",
      "Rank 1 Elapsed time is 0.000133113 seconds.\r\n"
     ]
    }
   ],
   "source": [
    "!mpirun -np 2 --oversubscribe python3 p2psendrecv.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting p2pnumpysendrecv.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile p2pnumpysendrecv.py\n",
    "from mpi4py import MPI\n",
    "import numpy\n",
    "\n",
    "comm = MPI.COMM_WORLD\n",
    "rank = comm.Get_rank()\n",
    "\n",
    "# initialize data\n",
    "if rank == 0:\n",
    "    data = numpy.arange(1000, dtype='i')\n",
    "elif rank == 1:\n",
    "    data = numpy.empty(1000, dtype='i')\n",
    "\n",
    "# measure communication time\n",
    "start = MPI.Wtime()\n",
    "if rank == 0:\n",
    "    comm.Send([data, MPI.INT], dest=1, tag=77)\n",
    "elif rank == 1:\n",
    "    comm.Recv([data, MPI.INT], source=0, tag=77)\n",
    "end = MPI.Wtime()\n",
    "elapsed = end - start\n",
    "\n",
    "print(\"Rank {} Elapsed time is {} seconds.\".format(rank, elapsed))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rank 0 Elapsed time is 0.000134116 seconds.\r\n",
      "Rank 1 Elapsed time is 4.1223e-05 seconds.\r\n"
     ]
    }
   ],
   "source": [
    "!mpirun -np 2 --oversubscribe python3 p2pnumpysendrecv.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise:**\n",
    "\n",
    "Modify `p2psendrecv.py` to communicate 1000 integers. How long does the communication take?\n",
    "\n",
    "Compare the results with the ones obtained from `p2pnumpysendrecv.py` (the example above).\n",
    "\n",
    "Which one is faster?"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
