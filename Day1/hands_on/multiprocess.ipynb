{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "54e718c1",
   "metadata": {},
   "source": [
    "# Parallel programming for CPU\n",
    "\n",
    "## process based parallelism via the multiprocessing module\n",
    "\n",
    "the [multiprocessing](https://docs.python.org/3/library/multiprocessing.html) - module mirrors threading, except that instead of a Thread class it provides a Process. Each Process is a true system process without shared memory, but multiprocessing provides features for sharing data and passing messages between them so that in many cases converting from threads to processes is as simple as changing a few import statements.\n",
    "\n",
    "multiprocessing is a package that supports spawning processes using an API similar to the threading module. The multiprocessing package offers both local and remote concurrency, effectively side-stepping the `Global Interpreter Lock` by using subprocesses instead of threads. Due to this, the multiprocessing module allows the programmer to fully leverage multiple processors on a given machine. It runs on both Unix and Windows.\n",
    "\n",
    "The multiprocessing module also introduces APIs which do not have analogs in the threading module. A prime example of this is the `Pool` object which offers a convenient means of parallelizing the execution of a function across multiple input values, distributing the input data across processes (data parallelism). The following example demonstrates the common practice of defining such functions in a module so that child processes can successfully import that module."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d0e5df2",
   "metadata": {},
   "source": [
    "### The Process class\n",
    "\n",
    "Similar to the ```Thread``` class it is used to spawn an additional process with a target function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a84ce725",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "My name:  My name: My name:  process-0\n",
      " process-1My name: My name:  \n",
      " process-3My result: process-4 2\n",
      "\n",
      "My result:  8\n",
      "process-2\n",
      "My result: My result:  6\n",
      "\n",
      "My result:  0\n",
      " 4\n"
     ]
    }
   ],
   "source": [
    "import multiprocessing\n",
    "import time\n",
    "\n",
    "def worker(num):\n",
    "    \"\"\" Worker function\n",
    "    \"\"\"\n",
    "    result = num * 2\n",
    "    my_name=multiprocessing.current_process().name\n",
    "    print('My name: ',my_name)\n",
    "    print('My result: ',result)\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    jobs = []\n",
    "    for i in range(5):\n",
    "        p = multiprocessing.Process(\n",
    "            target=worker, \n",
    "            daemon=False,\n",
    "            args=[i],\n",
    "            name=\"process-{}\".format(i)\n",
    "        )\n",
    "        jobs.append(p)\n",
    "        p.start()\n",
    "    \n",
    "    for j in jobs:\n",
    "        j.join()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc631031",
   "metadata": {},
   "source": [
    "Important difference with ```threading``` is that child processes need to import the script containing the traget function. It is therefore important to wrap the main part of the application with ```__main__``` to ensure this part is not executed by every child process. Alternatively the target function can be stored in a different file that can be then imported into the main.\n",
    "  \n",
    "From the example above, try to add the command  ```time.sleep(sec)``` (and pass different values of sec) to each worker and time both sequential and concurrent execution. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3c00c4e",
   "metadata": {},
   "source": [
    "#### Terminating a Process\n",
    "If a process appears hung or deadlocked it can be useful to be able to kill it forcibly. Calling ```terminate()``` on a process object kills the child process.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f57442f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5 doubled to 10 by: Normal_0\n",
      "10 doubled to 20 by: Normal_1\n",
      "20 doubled to 40 by: Normal_315 doubled to 30 by: Normal_2\n",
      "25 doubled to 50 by: Normal_4\n",
      "\n",
      "Process Test terminated.\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "from multiprocessing import Process, current_process\n",
    "\n",
    "def doubler(number):\n",
    "    \"\"\"\n",
    "    A doubling function that can be used by a process\n",
    "    \"\"\"\n",
    "    proc_name = current_process().name\n",
    "    if proc_name == \"Test\":\n",
    "        time.sleep(10)\n",
    "        \"Process Test: Done\"\n",
    "    else:\n",
    "        result = number * 2\n",
    "        print('{0} doubled to {1} by: {2}'.format(\n",
    "            number, result, proc_name))\n",
    " \n",
    " \n",
    "if __name__ == '__main__':\n",
    "    numbers = [5, 10, 15, 20, 25]\n",
    "    procs = []\n",
    " \n",
    "    for index, number in enumerate(numbers):\n",
    "        proc = Process(target=doubler, args=(number,),name='Normal_{}'.format(index))\n",
    "        procs.append(proc)\n",
    "        proc.start()\n",
    " \n",
    "    proc = Process(target=doubler, name='Test', args=(None,))\n",
    "    proc.start()\n",
    "    procs.append(proc)\n",
    " \n",
    "    for proc in procs:\n",
    "        proc.join(4)\n",
    "        if proc.is_alive():\n",
    "            proc.terminate()\n",
    "            print('Process {} terminated.'.format(proc.name))\n",
    "            \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51a9a8ea",
   "metadata": {},
   "source": [
    "---\n",
    "#### Lock\n",
    "\n",
    "The multiprocessing module supports locks in much the same way as the threading module does. \n",
    "\n",
    "All you need to do is import Lock, acquire it, do something and release it. Let’s take a look:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "d51d0e52",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing p_lock.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile p_lock.py\n",
    "from multiprocessing import Process, Lock, current_process\n",
    "import time\n",
    "\n",
    "def printer(item, lock):\n",
    "    \"\"\"\n",
    "    Prints out the item that was passed in\n",
    "    \"\"\"\n",
    "    lock.acquire()\n",
    "    try:\n",
    "        print(current_process().name, item)\n",
    "        time.sleep(1)\n",
    "    finally:\n",
    "        lock.release()\n",
    "        \n",
    "if __name__ == '__main__':\n",
    "    lock = Lock()\n",
    "    for item in range(5):\n",
    "        p = Process(target=printer, name=\"Proc-{}\".format(item), args=(item, lock))\n",
    "        p.start()\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "3ff143b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Proc-0 0\n",
      "Proc-1 1\n",
      "Proc-4 4\n",
      "Proc-3 3\n",
      "Proc-2 2\n"
     ]
    }
   ],
   "source": [
    "!python lock.py"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2dccc87e",
   "metadata": {},
   "source": [
    "#### Event\n",
    "\n",
    "Events are also used in the same way as for threadings: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "b82268fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting p_event.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile p_event.py\n",
    "from multiprocessing import Process, Event, current_process\n",
    "import time\n",
    "\n",
    "def wait_for_event(e):\n",
    "    \"\"\"Wait for the event to be set before doing anything\"\"\"\n",
    "    print(current_process().name,' waiting_for_event: starting')\n",
    "    e.wait()\n",
    "    print(current_process().name,' Done waiting : e.is_set()->', e.is_set())\n",
    "\n",
    "\n",
    "def wait_for_event_timeout(e, t):\n",
    "    \"\"\"Wait t seconds and then timeout\"\"\"\n",
    "    #print('wait_for_event_timeout: starting')\n",
    "    print(current_process().name,' waiting_for_event_timeout: starting')\n",
    "    e.wait(t)\n",
    "    print(current_process().name,' Done waiting : e.is_set()->', e.is_set())\n",
    "\n",
    "        \n",
    "        \n",
    "if __name__ == '__main__':\n",
    "    e = Event()\n",
    "    w1 = Process(\n",
    "        name='block',\n",
    "        target=wait_for_event,\n",
    "        args=(e,),\n",
    "    )\n",
    "    w1.start()\n",
    "\n",
    "    w2 = Process(\n",
    "        name='nonblock',\n",
    "        target=wait_for_event_timeout,\n",
    "        args=(e, 3),\n",
    "    )\n",
    "    w2.start()\n",
    "\n",
    "    print('main: waiting before calling Event.set()')\n",
    "    time.sleep(5)\n",
    "    e.set()\n",
    "    print('main: event is set')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "8f59cff4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "main: waiting before calling Event.set()\n",
      "block  waiting_for_event: starting\n",
      "nonblock  waiting_for_event_timeout: starting\n",
      "nonblock  Done waiting : e.is_set()-> False\n",
      "main: event is set\n",
      "block  Done waiting : e.is_set()-> True\n"
     ]
    }
   ],
   "source": [
    "!python  p_event.py"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adbae18d",
   "metadata": {},
   "source": [
    "Other constructs such as ```Semaphore``` and ```Conditions``` from the ```threading``` modules are also available in ```multiprocessing```, with very little differences between the two implementations.\n",
    "\n",
    "Try some of the examples showed before for ```threading``` with ```multiprocessing```."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c41124d1",
   "metadata": {},
   "source": [
    "### Share data between processes\n",
    "\n",
    "It is not advised to use shared states between processes, but if needed (and user is carful in managing them) ```multiprocessing``` offers two approach:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d2ec9d8",
   "metadata": {},
   "source": [
    "#### Shared memory\n",
    "\n",
    "```Value``` and ```Array``` can store data in shared memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "6cc686bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before:\n",
      "0.0\n",
      "[0, 1, 2, 3, 4, 5, 6, 7, 8, 9]\n",
      "After:\n",
      "3.1415927\n",
      "[0, -1, -2, -3, -4, -5, -6, -7, -8, -9]\n"
     ]
    }
   ],
   "source": [
    "from multiprocessing import Process, Value, Array\n",
    "\n",
    "def f(n, a):\n",
    "    n.value = 3.1415927\n",
    "    for i in range(len(a)):\n",
    "        a[i] = -a[i]\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    num = Value('d', 0.0)\n",
    "    arr = Array('i', range(10))\n",
    "\n",
    "    print(\"Before:\")    \n",
    "    print(num.value)\n",
    "    print(arr[:])\n",
    "\n",
    "    \n",
    "    p = Process(target=f, args=(num, arr))\n",
    "    p.start()\n",
    "    p.join()\n",
    "\n",
    "    print(\"After:\")    \n",
    "    print(num.value)\n",
    "    print(arr[:])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2521951",
   "metadata": {},
   "source": [
    "#### Server process\n",
    "\n",
    "A manager object returned by ```Manager()``` controls a server process which holds Python objects and allows other processes to manipulate them using proxies.\n",
    "\n",
    "Server processes can be also shared across network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "d0c20412",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before\n",
      "{}\n",
      "[0, 1, 2, 3, 4, 5, 6, 7, 8, 9]\n",
      "After\n",
      "{1: '1', '2': 2, 0.25: None}\n",
      "[9, 8, 7, 6, 5, 4, 3, 2, 1, 0]\n"
     ]
    }
   ],
   "source": [
    "from multiprocessing import Process, Manager\n",
    "\n",
    "\n",
    "def f(d, l):\n",
    "    d[1] = '1'\n",
    "    d['2'] = 2\n",
    "    d[0.25] = None\n",
    "    l.reverse()\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    with Manager() as manager:\n",
    "        d = manager.dict()\n",
    "        l = manager.list(range(10))\n",
    "\n",
    "        print(\"Before\")\n",
    "        print(d)\n",
    "        print(l)\n",
    "\n",
    "        \n",
    "        p = Process(target=f, args=(d, l))\n",
    "        p.start()\n",
    "        p.join()\n",
    "\n",
    "        print(\"After\")\n",
    "        print(d)\n",
    "        print(l)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c2b87c5",
   "metadata": {},
   "source": [
    "### The Pool class\n",
    "\n",
    "The ```Pool``` class is used to represent a pool of worker processes. It has methods which can allow you to offload tasks to the worker processes. Let’s look at a really simple example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "12d8911e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting p_pool.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile p_pool.py\n",
    "import multiprocessing as mp\n",
    "import time\n",
    "from random import randint\n",
    "\n",
    "def worker(sec):\n",
    "    \"\"\" \n",
    "    Worker function: sleeping num seconds\n",
    "    \"\"\"\n",
    "    print('Start sleeping {} in {}'.format(sec,mp.current_process().name))\n",
    "    time.sleep(sec)\n",
    "    print('Done sleeping {} in {}'.format(sec,mp.current_process().name))\n",
    "    return sec**2\n",
    "    \n",
    "def start_process():\n",
    "    print('Starting', mp.current_process().name)\n",
    "\n",
    "if __name__ == '__main__':\n",
    "\n",
    "    input_data = [10,8,6,4,2,1]\n",
    "    \n",
    "    print(\"INPUT:\",input_data)\n",
    "    \n",
    "    start_t = time.perf_counter()\n",
    "    \n",
    "    pool_size = 4\n",
    "    pool = mp.Pool(\n",
    "        processes=pool_size,\n",
    "        initializer=start_process,\n",
    "    )\n",
    "    pool_out = pool.map(worker, input_data)\n",
    "    pool.close()\n",
    "    pool.join()\n",
    "    \n",
    "    end_t = time.perf_counter()\n",
    "    \n",
    "    print('Total time =', end_t - start_t)\n",
    "    print('OUTPUT:', pool_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "41bf2cc0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INPUT: [10, 8, 6, 4, 2, 1]\n",
      "Starting ForkPoolWorker-1\n",
      "Starting ForkPoolWorker-2\n",
      "Starting ForkPoolWorker-3\n",
      "Starting ForkPoolWorker-4\n",
      "Start sleeping 10 in ForkPoolWorker-1\n",
      "Start sleeping 8 in ForkPoolWorker-2\n",
      "Start sleeping 6 in ForkPoolWorker-3\n",
      "Start sleeping 4 in ForkPoolWorker-4\n",
      "Done sleeping 4 in ForkPoolWorker-4\n",
      "Start sleeping 2 in ForkPoolWorker-4\n",
      "Done sleeping 6 in ForkPoolWorker-3\n",
      "Done sleeping 2 in ForkPoolWorker-4\n",
      "Start sleeping 1 in ForkPoolWorker-3\n",
      "Done sleeping 1 in ForkPoolWorker-3\n",
      "Done sleeping 8 in ForkPoolWorker-2\n",
      "Done sleeping 10 in ForkPoolWorker-1\n",
      "Total time = 10.041265523992479\n",
      "OUTPUT: [100, 64, 36, 16, 4, 1]\n"
     ]
    }
   ],
   "source": [
    "!python p_pool.py"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84435a25",
   "metadata": {},
   "source": [
    "Or using the ```map_async``` method to let processes do their work asynchronously"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "fc0bf6ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting p_pool_async.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile p_pool_async.py\n",
    "import multiprocessing as mp\n",
    "import time\n",
    "from random import randint\n",
    "\n",
    "def worker(sec):\n",
    "    \"\"\" \n",
    "    Worker function: sleeping num seconds\n",
    "    \"\"\"\n",
    "    print('Start sleeping {} in {}'.format(sec,mp.current_process().name))\n",
    "    time.sleep(2)\n",
    "    print('Done sleeping {} in {}'.format(sec,mp.current_process().name))\n",
    "    return sec**2\n",
    "    \n",
    "def start_process():\n",
    "    print('Starting', mp.current_process().name)\n",
    "\n",
    "if __name__ == '__main__':\n",
    "\n",
    "    input_data = [10,8,6,4,2,1]\n",
    "    \n",
    "    print(\"INPUT:\",input_data)\n",
    "    \n",
    "    start_t = time.perf_counter()\n",
    "    \n",
    "    pool_size = 4\n",
    "    pool = mp.Pool(\n",
    "        processes=pool_size,\n",
    "        initializer=start_process,\n",
    "    )\n",
    "    pool_out = pool.map_async(worker, input_data)\n",
    "    pool.close()\n",
    "    pool.join()\n",
    "    \n",
    "    end_t = time.perf_counter()\n",
    "    \n",
    "    print('Total time =', end_t - start_t)\n",
    "    print('OUTPUT:', pool_out.get())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "4d0d3029",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INPUT: [10, 8, 6, 4, 2, 1]\n",
      "Starting ForkPoolWorker-1\n",
      "Starting ForkPoolWorker-2\n",
      "Starting ForkPoolWorker-3\n",
      "Starting ForkPoolWorker-4\n",
      "Start sleeping 8 in ForkPoolWorker-2\n",
      "Start sleeping 10 in ForkPoolWorker-1\n",
      "Start sleeping 6 in ForkPoolWorker-3\n",
      "Start sleeping 4 in ForkPoolWorker-4\n",
      "Done sleeping 8 in ForkPoolWorker-2\n",
      "Done sleeping 10 in ForkPoolWorker-1\n",
      "Start sleeping 2 in ForkPoolWorker-1\n",
      "Done sleeping 6 in ForkPoolWorker-3\n",
      "Done sleeping 4 in ForkPoolWorker-4\n",
      "Start sleeping 1 in ForkPoolWorker-2\n",
      "Done sleeping 2 in ForkPoolWorker-1\n",
      "Done sleeping 1 in ForkPoolWorker-2\n",
      "Total time = 4.04389403690584\n",
      "OUTPUT: [100, 64, 36, 16, 4, 1]\n"
     ]
    }
   ],
   "source": [
    "!python p_pool_async.py"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8eafc663",
   "metadata": {},
   "source": [
    "### Communication between processes\n",
    "\n",
    "When it comes to communicating between processes, the multiprocessing modules has two primary methods: Queues and Pipes. The Queue implementation is actually both thread and process safe. Let’s take a look at a fairly simple example that’s based on the Queue code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "ce0b0c6f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating data and putting it on the queue\n",
      "data found to be processed: 5\n",
      "data processed: 10\n",
      "data found to be processed: 10\n",
      "data processed: 20\n",
      "data found to be processed: 13\n",
      "data processed: 26\n",
      "data found to be processed: -1\n",
      "data processed: -2\n",
      "[5, 10, 13, -1]\n"
     ]
    }
   ],
   "source": [
    "from multiprocessing import Process, Queue\n",
    "import time \n",
    "\n",
    "sentinel = -1\n",
    " \n",
    "def creator(data, q):\n",
    "    \"\"\"\n",
    "    Creates data to be consumed and waits for the consumer\n",
    "    to finish processing\n",
    "    \"\"\"\n",
    "    print('Creating data and putting it on the queue')\n",
    "    for item in data:\n",
    "        q.put(item)\n",
    " \n",
    " \n",
    "def my_consumer(q):\n",
    "    \"\"\"\n",
    "    Consumes some data and works on it\n",
    " \n",
    "    In this case, all it does is double the input\n",
    "    \"\"\"\n",
    "    while True:\n",
    "        data = q.get()\n",
    "        print('data found to be processed: {}'.format(data))\n",
    "        processed = data * 2\n",
    "        time.sleep(1)\n",
    "        print('data processed: {}'.format(processed))\n",
    " \n",
    "        if data is sentinel:\n",
    "            break\n",
    " \n",
    " \n",
    "if __name__ == '__main__':\n",
    "    q = Queue()\n",
    "    data = [5, 10, 13, -1]\n",
    "    process_one = Process(target=creator, args=(data, q))\n",
    "    process_two = Process(target=my_consumer, args=(q,))\n",
    "    process_one.start()\n",
    "    process_two.start()\n",
    " \n",
    "    q.close()\n",
    "    q.join_thread()\n",
    " \n",
    "    process_one.join()\n",
    "    process_two.join()\n",
    "    print(data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b716464c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
